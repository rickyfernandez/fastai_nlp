{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction as sklearn_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and term document matrix creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "??URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ricardofernandez/.fastai/data/imdb_sample')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/ricardofernandez/.fastai/data/imdb_sample/texts.csv')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'texts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 800, True: 200})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df.is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'negative': 524, 'positive': 476})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
    "                 .split_from_df(col=2)\n",
    "                 .label_from_df(cols=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj un - xxunk - believable ! xxmaj meg xxmaj ryan does n't even look her usual xxunk lovable self in this , which normally makes me forgive her shallow xxunk acting xxunk . xxmaj hard to believe she was the producer on this dog . xxmaj plus xxmaj kevin xxmaj kline : what kind of suicide trip has his career been on ? xxmaj xxunk ... xxmaj xxunk ! ! ! xxmaj finally this was directed by the guy who did xxmaj big xxmaj xxunk ? xxmaj must be a replay of xxmaj jonestown - hollywood style . xxmaj xxunk !"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.train.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category negative"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.train.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.train.x), len(movie_reviews.valid.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6008, 19161)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.vocab.itos), len(movie_reviews.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.stoi['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'language'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[917]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that', 'this', '\"', \"'s\", '\\n \\n ', '-', 'was', 'as', 'for', 'movie']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sollett'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[6007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'the',\n",
       " '.',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'it',\n",
       " 'in',\n",
       " 'i']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.train.x[5].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxunk'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[movie_reviews.vocab.stoi[\"Rrrick\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'language'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[movie_reviews.vocab.stoi[\"language\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = movie_reviews.train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.Text"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    5, 4619,   25,    0,   25,  867,   52,    5, 3776,    5, 1800,   95,   37,   85,  191,   64,  935,\n",
       "          0, 2738,  517,   18,   21,   11,   84, 2417,  192,   88, 3777,   64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our term-document matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter([4,3,8,8,4,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2, 3: 1, 8: 3})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([2, 1, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([4, 3, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our version of CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 1,\n",
       "         5: 32,\n",
       "         21: 3,\n",
       "         71: 1,\n",
       "         189: 1,\n",
       "         748: 1,\n",
       "         288: 1,\n",
       "         285: 1,\n",
       "         63: 2,\n",
       "         221: 1,\n",
       "         666: 2,\n",
       "         59: 1,\n",
       "         13: 4,\n",
       "         2705: 1,\n",
       "         14: 6,\n",
       "         2875: 1,\n",
       "         11: 10,\n",
       "         18: 2,\n",
       "         358: 1,\n",
       "         0: 32,\n",
       "         77: 1,\n",
       "         15: 6,\n",
       "         478: 1,\n",
       "         1833: 1,\n",
       "         50: 3,\n",
       "         9: 10,\n",
       "         319: 1,\n",
       "         6: 1,\n",
       "         2743: 1,\n",
       "         12: 1,\n",
       "         115: 1,\n",
       "         4126: 1,\n",
       "         197: 2,\n",
       "         1331: 1,\n",
       "         25: 2,\n",
       "         324: 1,\n",
       "         10: 7,\n",
       "         3963: 1,\n",
       "         16: 4,\n",
       "         74: 1,\n",
       "         24: 3,\n",
       "         2817: 1,\n",
       "         5821: 1,\n",
       "         2595: 1,\n",
       "         710: 1,\n",
       "         3429: 1,\n",
       "         84: 1,\n",
       "         149: 1,\n",
       "         20: 1,\n",
       "         26: 1,\n",
       "         605: 1,\n",
       "         378: 1,\n",
       "         1057: 1,\n",
       "         251: 1,\n",
       "         258: 1,\n",
       "         1346: 1,\n",
       "         194: 1,\n",
       "         239: 1,\n",
       "         49: 1,\n",
       "         2764: 1,\n",
       "         1335: 1,\n",
       "         409: 1,\n",
       "         27: 3,\n",
       "         45: 1,\n",
       "         594: 1,\n",
       "         850: 1,\n",
       "         109: 1,\n",
       "         2601: 1,\n",
       "         430: 1,\n",
       "         1902: 1,\n",
       "         541: 1,\n",
       "         54: 2,\n",
       "         1107: 1,\n",
       "         608: 1,\n",
       "         404: 1,\n",
       "         736: 1,\n",
       "         44: 1,\n",
       "         204: 1,\n",
       "         23: 1,\n",
       "         3480: 1,\n",
       "         4736: 1,\n",
       "         456: 1,\n",
       "         4051: 1,\n",
       "         2420: 1,\n",
       "         30: 1,\n",
       "         337: 1,\n",
       "         966: 1,\n",
       "         58: 1,\n",
       "         207: 1,\n",
       "         2110: 1,\n",
       "         571: 1,\n",
       "         5035: 1,\n",
       "         579: 1,\n",
       "         1843: 1,\n",
       "         52: 1})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter((movie_reviews.valid.x)[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxmaj'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxup'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj this very funny xxmaj british comedy shows what might happen if a section of xxmaj london , in this case xxmaj xxunk , were to xxunk itself independent from the rest of the xxup uk and its laws , xxunk & post - war xxunk . xxmaj merry xxunk is what would happen . \n",
       " \n",
       "  xxmaj the explosion of a wartime bomb leads to the xxunk of ancient xxunk which show that xxmaj xxunk was xxunk to the xxmaj xxunk of xxmaj xxunk xxunk ago , a small historical xxunk long since forgotten . xxmaj to the new xxmaj xxunk , however , this is an unexpected opportunity to live as they please , free from any xxunk from xxmaj xxunk . \n",
       " \n",
       "  xxmaj stanley xxmaj xxunk is excellent as the minor city xxunk who suddenly finds himself leading one of the world 's xxunk xxunk . xxmaj xxunk xxmaj margaret xxmaj xxunk is a delight as the history professor who sides with xxmaj xxunk . xxmaj others in the stand - out cast include xxmaj xxunk xxmaj xxunk , xxmaj paul xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk & xxmaj sir xxmaj michael xxmaj xxunk . \n",
       " \n",
       "  xxmaj welcome to xxmaj xxunk !"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(movie_reviews.valid.x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [4,3]\n",
    "a.extend([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 3, 4]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_doc_matrix(label_list, vocab_len):\n",
    "    j_indices = []\n",
    "    indptr = []\n",
    "    values = []\n",
    "    indptr.append(0)\n",
    "    \n",
    "    for i, doc in enumerate(label_list):\n",
    "        feature_counter = Counter(doc.data)\n",
    "        j_indices.extend(feature_counter.keys())\n",
    "        values.extend(feature_counter.values())\n",
    "        indptr.append(len(j_indices))\n",
    "      \n",
    "    #print(len(indptr))\n",
    "    return scipy.sparse.csr_matrix((values, j_indices, indptr),\n",
    "                                  shape=(len(indptr)-1, vocab_len),\n",
    "                                  dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.3 ms, sys: 4.06 ms, total: 47.3 ms\n",
      "Wall time: 45.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_term_doc = get_term_doc_matrix(movie_reviews.valid.x,\n",
    "                                  len(movie_reviews.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 132 ms, sys: 8.97 ms, total: 141 ms\n",
      "Wall time: 137 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trn_term_doc = get_term_doc_matrix(movie_reviews.train.x,\n",
    "                                  len(movie_reviews.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 6008)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " trn_term_doc[:,-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6008)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sollett']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[32,  0,  1,  0, ...,  1,  0,  0, 10],\n",
       "        [ 9,  0,  1,  0, ...,  1,  0,  0,  7],\n",
       "        [ 6,  0,  1,  0, ...,  0,  0,  0, 12],\n",
       "        [78,  0,  1,  0, ...,  0,  0,  0, 44],\n",
       "        ...,\n",
       "        [ 8,  0,  1,  0, ...,  0,  0,  0,  8],\n",
       "        [43,  0,  1,  0, ...,  8,  1,  0, 25],\n",
       "        [ 7,  0,  1,  0, ...,  1,  0,  0,  9],\n",
       "        [19,  0,  1,  0, ...,  2,  0,  0,  5]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.todense()[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 value 78\n",
      "index 1 value 0\n",
      "index 2 value 1\n",
      "index 3 value 0\n",
      "index 4 value 0\n",
      "index 5 value 52\n",
      "index 6 value 0\n",
      "index 7 value 0\n",
      "index 8 value 0\n",
      "index 9 value 44\n"
     ]
    }
   ],
   "source": [
    "c = Counter(movie_reviews.valid.x[3].data)\n",
    "for i in range(10):\n",
    "    print(f\"index {i} value {c[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxeos'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos i saw this movie once as a kid on the late - late show and fell in love with it . \n",
       " \n",
       "  xxmaj it took 30 + years , but i recently did find it on xxup dvd - it was n't cheap , either - in a xxunk that xxunk in war movies . xxmaj we watched it last night for the first time . xxmaj the audio was good , however it was grainy and had the trailers between xxunk . xxmaj even so , it was better than i remembered it . i was also impressed at how true it was to the play . \n",
       " \n",
       "  xxmaj the xxunk is around here xxunk . xxmaj if you 're xxunk in finding it , fire me a xxunk and i 'll see if i can get you the xxunk . xxunk"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = movie_reviews.valid.x[1]; review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc[1,movie_reviews.vocab.stoi[\"late\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200x6008 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27848 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x6008 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 81 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, (144,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc[1].sum(), movie_reviews.valid[1][0].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos i saw this movie once as a kid on the late - late show and fell in love with it . \n",
      " \n",
      "  xxmaj it took 30 + years , but i recently did find it on xxup dvd - it was n't cheap , either - in a xxunk that xxunk in war movies . xxmaj we watched it last night for the first time . xxmaj the audio was good , however it was grainy and had the trailers between xxunk . xxmaj even so , it was better than i remembered it . i was also impressed at how true it was to the play . \n",
      " \n",
      "  xxmaj the xxunk is around here xxunk . xxmaj if you 're xxunk in finding it , fire me a xxunk and i 'll see if i can get you the xxunk . xxunk\n"
     ]
    }
   ],
   "source": [
    "string = \"\"\n",
    "for i in review.data:\n",
    "    string += \" \" + movie_reviews.vocab.itos[i]\n",
    "print(string[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(val_term_doc[1].todense() != 0)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(review.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state',\n",
       " 'street',\n",
       " 'impossible',\n",
       " 'clever',\n",
       " 'development',\n",
       " 'concept',\n",
       " 'william',\n",
       " 'worked',\n",
       " 'adventure',\n",
       " 'church',\n",
       " 'unlike',\n",
       " 'hold',\n",
       " 'lots',\n",
       " 'premise',\n",
       " 'shooting',\n",
       " 'washington',\n",
       " 'sick',\n",
       " 'effect',\n",
       " 'waiting',\n",
       " 'singing']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[1000:1020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13154"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.vocab.stoi) - len(movie_reviews.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxunk'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk = []\n",
    "for word, num in movie_reviews.vocab.stoi.items():\n",
    "    if num == 0:\n",
    "        unk.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13155"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'bleeping',\n",
       " 'pert',\n",
       " 'ticky',\n",
       " 'schtick',\n",
       " 'whoosh',\n",
       " 'banzai',\n",
       " 'chill',\n",
       " 'wooofff',\n",
       " 'cheery',\n",
       " 'superstars',\n",
       " 'fashionable',\n",
       " 'cruelly',\n",
       " 'separating',\n",
       " 'mistreat',\n",
       " 'tensions',\n",
       " 'religions',\n",
       " 'baseness',\n",
       " 'nobility',\n",
       " 'puro',\n",
       " 'disowned',\n",
       " 'option',\n",
       " 'faults',\n",
       " 'dignified',\n",
       " 'realisation',\n",
       " 'reconciliation',\n",
       " 'mrs',\n",
       " 'iyer',\n",
       " 'heartbreaking',\n",
       " 'histories']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.y.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trn_term_doc\n",
    "y = movie_reviews.train.y\n",
    "val_y = movie_reviews.valid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoryList (200 items)\n",
       "positive,positive,positive,positive,positive\n",
       "Path: /Users/ricardofernandez/.fastai/data/imdb_sample"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = y.c2i['positive']\n",
    "negative = y.c2i['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxunk'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = movie_reviews.vocab\n",
    "v.itos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grab all rows with negative sentiment and sum total word counts for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<417x6008 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 60554 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[y.items == negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7154,    0,  417,    0, ...,    0,    3,    3,    3]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(x[y.items == negative].sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7154,    0,  417,    0, ...,    0,    3,    3,    3], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(np.asarray(x[y.items == negative].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6471,    0,  383,    0, ...,    3,    0,    0,    0], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(np.asarray(x[y.items == positive].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.squeeze(np.asarray(x[y.items == positive].sum(0)))\n",
    "p0 = np.squeeze(np.asarray(x[y.items == negative].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6471,     0,   383,     0,     0, 10267,   674,    57,     0,  5260], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6008, 6008, 6008)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p1), len(p0), len(v.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4166666666666665"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[v.stoi[\"loved\"]]/p0[v.stoi[\"loved\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38461538461538464"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[v.stoi[\"hate\"]]/p0[v.stoi[\"hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1977"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stoi['hated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.argwhere((x[:,1977] > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15,   0],\n",
       "       [ 49,   0],\n",
       "       [304,   0],\n",
       "       [351,   0],\n",
       "       [393,   0],\n",
       "       [612,   0],\n",
       "       [695,   0],\n",
       "       [773,   0]], dtype=int32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj as if the storyline was n't depressing enough , this movie shows xxunk being xxunk graphically in a slaughterhouse for all of five minutes while the protagonist is xxunk her early life as a butcher . xxmaj weird stuff . xxmaj then there 's the core premise of the hero / heroine who goes and cuts his dick off because a he 's xxunk - ten with at work says he would have gone with him if he was a girl . xxmaj is this person a psycho , a xxunk , just a doomed queen who takes things too far ? xxmaj and what sort of xxunk childhood did he have ? xxmaj just that he did n't get adopted and had to live it out with xxunk who at first loved him and then later hated him because he was xxunk . xxmaj he tries to explain to us the reasons he did what he did , but it 's really really so hard to xxunk . xxmaj such sad and unusual self destruction . xxmaj was it supposed to be funny ? xxmaj what was it all about really ?"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.train.x[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15,  49, 304, 351, 393, 612, 695, 773], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.argwhere((x[:,1977] > 0))[:,0]; a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   3,  10,  11, ..., 787, 789, 790, 797])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.argwhere(y.items==positive)[:,0]; b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 383)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a), len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{393, 612, 695}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(a).intersection(set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbos xxmaj xxunk , yeah this episode is extremely underrated . \\n \\n  xxmaj even though there is a xxup lot of bad writing and acting at parts . i think the good over wins the bad . \\n \\n  i love the xxunk parts and the big ' twist ' at the end . i absolutely love that scene when xxmaj michelle xxunk xxmaj tony . xxmaj it 's actually one of my favorite scenes of xxmaj season 1 . \\n \\n  xxmaj for some reason , people have always hated the xxmaj xxunk episodes , yet i have always liked them . xxmaj they 're not the best , in terms of writing . but the theme really does interest me , \\n \\n  i 'm gon na give it a xxup three star , but if the writing were a little more consistent i 'd give it xxup four .\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = movie_reviews.train.x[695]\n",
    "review.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stoi['loved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  15,  29,  69,  75,  79, 174, 185, 200, 205, 262, 296, 303, 333, 350, 351, 398, 407, 440, 489, 496, 528,\n",
       "       538, 600, 602, 605, 627, 642, 657, 660, 700, 712, 729, 735, 755, 767, 785], dtype=int32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.argwhere((x[:,535] > 0))[:,0]; a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   4,   5, ..., 795, 796, 798, 799])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.argwhere(y.items==negative)[:,0]; b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{15, 200, 205, 303, 351, 398, 600, 605, 642, 700, 729, 767}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(a).intersection(set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj this is not really a zombie film , if we \\'re xxunk zombies as the dead walking around . xxmaj here the protagonist , xxmaj xxunk xxmaj louque ( played by an xxunk young xxmaj dean xxmaj xxunk ) , xxunk control of a method to create zombies , though in fact , his \\' method \\' is to mentally project his thoughts and control other living people \\'s minds turning them into xxunk slaves . xxmaj this is an interesting concept for a movie , and was done much more effectively by xxmaj xxunk xxmaj lang in his series of \\' xxmaj dr. xxmaj mabuse \\' films , including \\' xxmaj dr. xxmaj mabuse the xxmaj xxunk \\' ( xxunk ) and \\' xxmaj the xxmaj testament of xxmaj dr. xxmaj mabuse \\' ( 1933 ) . xxmaj here it is unfortunately xxunk to his quest to regain the love of his former fiancée , xxmaj claire xxmaj duvall ( played by the xxmaj anne xxmaj xxunk look alike with a bad xxunk , xxmaj dorothy xxmaj stone ) which is really the major theme . \\n \\n  xxmaj the movie has an intriguing beginning , as xxmaj louque is sent on a military xxunk expedition to xxmaj xxunk to end the cult of zombies that came from there . xxmaj at some type of compound ( where we get great 30s sets and clothes ) he xxunk his xxunk to xxmaj claire , and then barely five minutes later , she gives him back his ring xxunk her love for his pal , xxmaj xxunk xxmaj greyson ( xxmaj robert xxmaj xxunk ) . xxmaj it \\'s unintentionally funny the way they talk to each other without making eye contact . xxmaj this would have been a great movie for \\' xxmaj mystery xxmaj science xxmaj theater xxunk \\' , if they had n\\'t already xxunk it . \\n \\n  xxmaj it \\'s never shown how xxmaj louque actually learns the \\' xxunk \\' secret , but he then uses it to kill his enemies , create a giant army of xxunk carrying soldiers and body guards . xxmaj we wo n\\'t see such sheer force of will until xxmaj john xxmaj xxunk in \\' xxmaj the xxmaj brain xxmaj from xxmaj planet xxmaj xxunk \\' ( xxunk ) . \\n \\n  xxmaj finally xxmaj claire xxunk to marry him if he will let xxmaj greyson live and return to xxmaj america . xxmaj louque agrees , but actually turns him into one of his xxunk slaves . xxmaj on their wedding night he realizes that xxmaj claire will only begin to love him if he gives up his \\' powers . \\' xxmaj to gain her love , he does so , causing the \\' revolt \\' of the title , in which all his slaves xxunk and attack his compound and kill him . xxmaj greyson xxunk xxmaj claire , and we seem to be at the end of a parable : \" xxmaj whom the xxunk would destroy , they first make mad . \" \\n \\n  xxmaj so really then , it \\'s not that bad of a film , despite the low imdb rating it currently has . xxmaj on repeated viewings ( ? ) one can see the xxunk in the well formed script ! xxmaj dean xxmaj xxunk had yet to develop into a good actor , and is almost unrecognizable in his xxunk -- is that really his own hair ? xxmaj we remember him more for his xxunk , old man roles in \\' xxmaj white xxmaj christmas \\' ( xxunk ) , \\' x xxmaj the xxmaj unknown \\' ( 1956 ) and \\' xxmaj king xxmaj xxunk \\' ( 1958 ) . xxmaj the story xxunk a lot of its basic themes from the xxmaj xxunk brothers better , earlier film \\' xxmaj white xxmaj zombie \\' ( xxunk ) in which xxunk xxmaj robert xxmaj xxunk ( as xxmaj charles xxmaj xxunk ) uses \\' xxunk \\' to win the love of xxmaj xxunk xxmaj xxunk ( as xxmaj xxunk xxmaj parker ) . \\n \\n  xxmaj if you want real zombie movies ( of which there are hundreds ! ) i \\'d start with \\' xxmaj white xxmaj zombie \\' ( xxunk ) , \\' xxmaj king of the xxmaj zombies \\' ( xxunk ) , \\' i xxmaj walked with a xxmaj zombie \\' ( xxunk ) , \\' xxmaj night of the xxmaj living xxmaj dead \\' ( xxunk ) , \\' xxmaj the xxmaj last xxmaj man on xxmaj earth \\' ( 1964 ) and its two xxunk . xxmaj in the modern era of classy films , there are \\' xxmaj horror xxmaj express \\' ( 1972 ) , \\' xxmaj the xxmaj xxunk and the xxmaj xxunk \\' ( xxunk ) , \\' 28 xxmaj days xxmaj later \\' ( 2002 ) and its sequel , as well as many , many , others too numerous to mention . \\n \\n  xxmaj this one is not really a zombie film . xxmaj judging this movie on its own terms , it \\'s more of a semi - xxmaj gothic romance . xxmaj as such it ranks a little below some of xxmaj universal \\'s bottom billed b horror movies of the late 30s and early xxunk . xxmaj so i \\'ll give it a 5 .'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = movie_reviews.train.x[792]\n",
    "review.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))\n",
    "p0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below is not correct for bayes as we should be calculating p(w|positive) = p(w,positive)/sum(p(w_k, positive)) over vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "pr1 = (p1+alpha)/((y.items==positive).sum() + alpha)\n",
    "pr0 = (p0+alpha)/((y.items==negative).sum() + alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr1[pr1<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.015487,  0.084839,  0.      ,  0.084839, ...,  1.471133, -1.301455, -1.301455, -1.301455])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.log(pr1/pr0); r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest = np.argpartition(r, -10)[-10:]\n",
    "smallest = np.argpartition(r, 10)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sport',\n",
       " 'davies',\n",
       " 'gilliam',\n",
       " 'fanfan',\n",
       " 'biko',\n",
       " 'felix',\n",
       " 'noir',\n",
       " 'jabba',\n",
       " 'astaire',\n",
       " 'jimmy']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most positive words\n",
    "[v.itos[k] for k in biggest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(trn_term_doc[:,v.stoi['biko']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos \" xxmaj the xxmaj true xxmaj story xxmaj of xxmaj the xxmaj friendship xxmaj that xxmaj shook xxmaj south xxmaj africa xxmaj and xxmaj xxunk xxmaj the xxmaj world . \" \n",
       " \n",
       "  xxmaj richard xxmaj attenborough , who directed \" a xxmaj bridge xxmaj too xxmaj far \" and \" xxmaj gandhi \" , wanted to bring the story of xxmaj steve xxmaj biko to life , and the journey and trouble that xxunk xxmaj donald xxmaj woods went through in order to get his story told . xxmaj the films uses xxmaj wood 's two books for it 's information and basis - \" xxmaj biko \" and \" xxmaj asking for xxmaj trouble \" . \n",
       " \n",
       "  xxmaj the film takes place in the late 1970 's , in xxmaj south xxmaj africa . xxmaj south xxmaj africa is in the grip of the terrible apartheid , which keeps the blacks separated from the whites and xxunk the whites as the superior race . xxmaj the blacks are forced to live in xxunk on the xxunk of the cities and xxunk , and they come under frequent xxunk by the police and the army . xxmaj we are shown a dawn xxunk on a xxunk , as xxunk and armed police force their way through the camp beating and even killing the inhabitants . xxmaj then we are introduced to xxmaj donald xxmaj woods ( xxmaj kevin xxmaj kline ) , who is the editor of a popular newspaper . xxmaj after xxunk a negative story about black xxunk xxmaj steve xxmaj biko ( xxmaj denzel xxmaj washington ) , xxmaj woods goes to meet with him . xxmaj the two are xxunk of each other at first , but they soon become good friends and xxmaj biko shows the horrors of the apartheid system from a black persons point of view to xxmaj woods . xxmaj this xxunk xxmaj woods to speak out against what 's happening around him , and makes him desperate to bring xxmaj steve xxmaj biko 's story out of the xxunk of the white man 's xxmaj south xxmaj africa and to the world . xxmaj soon , xxmaj steve xxmaj biko is arrested and is killed in prison . xxmaj now xxmaj woods and his family are daring to escape from xxmaj south xxmaj africa to xxmaj england , where xxmaj woods can xxunk his book about xxmaj steve xxmaj biko and the apartheid . \n",
       " \n",
       "  xxmaj when i first heard of \" xxmaj cry xxmaj freedom \" , i was under the impression that it was a movie completely dedicated to the life of xxmaj steve xxmaj biko . i had never actually heard of xxmaj steve xxmaj biko before i seen this film , as the events in this film were really before my time . xxmaj but it 's more about the story of xxmaj donald xxmaj woods and his journey across the border into xxmaj xxunk as he tried to xxunk the xxmaj south xxmaj african xxunk . xxmaj woods was put on a five year type house xxunk after xxmaj steve xxmaj biko was killed . xxmaj so in order to xxunk his xxunk on xxmaj steve xxmaj biko , he had to escape . xxmaj because the xxunk would be considered xxunk in xxmaj south xxmaj africa and that could have resulted in xxmaj woods meeting a fate similar to that of xxmaj biko 's . xxmaj the real xxmaj donald xxmaj woods and his wife acted as xxunk to this film . \n",
       " \n",
       "  xxmaj denzel xxmaj washington is only in the film for the first hour , and i was disappointed with that as i was expecting to see him for the entire movie . xxmaj but he was amazing as xxmaj steve xxmaj biko , and captured his personality from what i 've read really well and his accent sounded perfect . xxmaj his performance earned him an xxmaj oscar nomination for xxmaj best xxmaj supporting xxmaj actor . xxmaj kevin xxmaj kline delivers a excellent and thought - xxunk performance as xxmaj donald xxmaj woods , and xxmaj penelope xxmaj xxunk is excellent as his wife xxmaj xxunk . \n",
       " \n",
       "  xxmaj filming took place in xxmaj xxunk , as needless to say problems xxunk when they tried to film it in xxmaj south xxmaj africa . xxmaj while in xxmaj south xxmaj africa , the xxmaj south xxmaj african xxunk followed the film crew everywhere , so they got the bad xxunk and they pulled out and went to xxunk xxmaj xxunk instead . xxmaj despite everything , and the fact that the apartheid did n't end ' xxunk seven years later , \" xxmaj cry xxmaj freedom \" was n't xxunk in xxmaj south xxmaj africa . xxmaj but xxunk showing the movie received bomb threats . \n",
       " \n",
       "  xxmaj richard xxmaj attenborough brings the horrors of the apartheid to the screen with extreme force and determination . xxmaj he does n't hold back at the end of the movie when showing what was supposed to be a xxunk xxunk by students in a xxunk , turns into a massacre when police open fire on them . xxmaj the film ends with the names of all the anti - apartheid xxunk who died in prison , and the explanations for their deaths . xxmaj many had \" xxmaj no xxmaj explanation \" . xxmaj quite a few were \" xxmaj xxunk \" , which is hard to believe , and many more either fell from the top of the xxunk or were \" xxmaj suicide from xxmaj hanging \" . xxmaj no one will ever know what really happened to them , but i think it 's fair to say that none of these men died at their own hands , but at the hands of others ; or to be more xxunk , at the hands of the police . \n",
       " \n",
       "  \" xxmaj cry xxmaj freedom \" is a must - see movie for it 's portrayal and story of xxmaj steve xxmaj biko . xxmaj it 's also a xxunk and xxunk portrayal of a beautiful land divided and in the xxunk grips of racial xxunk and violence ."
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.train.x[515]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above is a long review with the word beko used many times, you can see that makes beko a strong feature but this is not correct. This is a flaw that has to be corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "negative reveiws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'crap',\n",
       " 'crater',\n",
       " 'porn',\n",
       " 'disappointment',\n",
       " 'dog',\n",
       " 'vargas',\n",
       " 'naschy',\n",
       " 'fuqua',\n",
       " 'soderbergh']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.itos[k] for k in smallest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(trn_term_doc[:,v.stoi[\"soderbergh\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj xxunk , after xxunk ) , i can xxunk join both xxunk of \" xxmaj at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \n",
       " \n",
       "  xxmaj it 's usually satisfying to watch a film director change his style / subject , but xxmaj soderbergh 's most recent stinker , xxmaj the xxmaj girlfriend xxmaj xxunk ) , was also missing a story , so narrative ( and editing ? ) seem to suddenly be xxmaj soderbergh 's main challenge . xxmaj strange , after xxunk years in the business . xxmaj he was probably never much good at narrative , just xxunk it well inside \" edgy \" projects . \n",
       " \n",
       "  xxmaj none of this excuses him this present , almost diabolical failure . xxmaj as xxmaj david xxmaj xxunk xxunk , \" two parts of xxmaj che do n't ( even ) make a whole \" . \n",
       " \n",
       "  xxmaj epic xxunk in name only , xxmaj che(2008 ) barely qualifies as a feature film ! xxmaj it certainly has no legs , xxunk as except for its xxunk ultimate resolution forced upon it by history , xxmaj soderbergh 's xxunk - long xxunk just goes nowhere . \n",
       " \n",
       "  xxmaj even xxmaj margaret xxmaj xxunk , the more xxunk of xxmaj australia 's xxmaj at xxmaj the xxmaj movies duo , noted about xxmaj soderbergh 's xxunk waste of ( xxup xxunk digital xxunk ) : \" you 're in the woods ... xxunk in the woods ... xxunk in the woods ... \" . i too am surprised xxmaj soderbergh did n't give us another xxunk of xxup that somewhere between his xxunk two xxmaj parts , because he still left out massive xxunk of xxmaj che 's \" xxunk \" life ! \n",
       " \n",
       "  xxmaj for a xxunk of an important but infamous historical figure , xxmaj soderbergh xxunk xxunk , if not deliberately insults , his audiences by \n",
       " \n",
       "  1 . never providing most of xxmaj che 's story ; \n",
       " \n",
       "  2 . xxunk xxunk film xxunk with mere xxunk xxunk ; \n",
       " \n",
       "  3 . xxunk both true xxunk and a narrative of events ; \n",
       " \n",
       "  4 . barely developing an idea , or a character ; \n",
       " \n",
       "  5 . remaining xxunk episodic ; \n",
       " \n",
       "  6 . xxunk proper context for scenes --- whatever we do get is xxunk in xxunk xxunk ; \n",
       " \n",
       "  7 . xxunk xxunk all audiences ( even xxmaj spanish - xxunk will be confused by the xxunk xxunk in xxmaj english ) ; and \n",
       " \n",
       "  8 . xxunk xxunk his main subject into one dimension . xxmaj why , at xxup this late stage ? xxmaj the t - shirt franchise has been a success ! \n",
       " \n",
       "  xxmaj our sense of xxunk is surely due to xxmaj peter xxmaj xxunk and xxmaj benjamin xxunk xxmaj xxunk xxunk their screenplay solely on xxmaj xxunk 's memoirs . xxmaj so , like a poor student who has read only xxup one of his xxunk xxunk for his xxunk , xxmaj soderbergh 's product is xxunk limited in perspective . \n",
       " \n",
       "  xxmaj the audience is held captive within the same xxunk knowledge , scenery and circumstances of the \" revolutionaries \" , but that does n't xxunk our sympathy . xxmaj instead , it xxunk on us that \" xxmaj ah , xxmaj soderbergh 's trying to xxunk his audiences the same as the xxmaj latino peasants were at the time \" . xxmaj but these are the xxup same illiterate xxmaj latino peasants who xxunk out the good doctor to his enemies . xxmaj why does xxmaj soderbergh feel the need to xxunk us with them , and keep us equally mentally captive ? xxmaj such audience xxunk must have a purpose . \n",
       " \n",
       "  xxmaj part2 is more xxunk than xxmaj part1 , but it 's literally mind - numbing with its repetitive bush - bashing , misery of xxunk , and lack of variety or character xxunk . deltoro 's xxmaj che has no opportunity to grow as a person while he struggles to xxunk his own ill - xxunk troops . xxmaj the only xxunk is the humour as xxmaj che deals with his sometimes deeply ignorant \" revolutionaries \" , some of whom xxunk lack self - control around local peasants or food . xxmaj we certainly get no insight into what caused the conditions , nor any xxunk xxunk of their xxunk xxunk , such as it was . \n",
       " \n",
       "  xxmaj part2 's xxunk xxunk remains xxunk episodic : again , nothing is telegraphed or xxunk . xxmaj thus even the scenes with xxmaj xxunk xxmaj xxunk ( xxmaj xxunk xxmaj xxunk ) are unexpected and disconcerting . xxmaj any xxunk events are portrayed xxunk and xxmaj latino - xxunk , with xxmaj part1 's interviews xxunk by time - xxunk xxunk between the corrupt xxmaj xxunk president ( xxmaj xxunk de xxmaj xxunk ) and xxup us xxmaj government xxunk promising xxup cia xxunk ( ! ) . \n",
       " \n",
       "  xxmaj the rest of xxmaj part2 's \" woods \" and day - for - night blue xxunk just xxunk the audience until they 're xxunk the xxunk . \n",
       " \n",
       "  xxmaj perhaps deltoro felt too xxunk the frustration of many non - xxmaj american xxmaj latinos about never getting a truthful , xxunk history of xxmaj che 's xxunk within their own countries . xxmaj when foreign xxunk still wo n't deliver a free press to their people -- for whatever reason -- then one can see how a popular xxmaj american indie producer might set out to xxunk the not - so - well - read ( \" i may not be able to read or write , but i 'm xxup not xxunk . xxmaj the xxmaj inspector xxmaj xxunk ) ) out to their own local xxunk . xxmaj the film 's obvious xxunk and gross over - xxunk hint very strongly that it 's aiming only at the xxunk of the less - informed xxup who xxup still xxup speak xxup little xxmaj english . xxmaj if they did , they 'd have read xxunk on the subject already , and xxunk the relevant social issues amongst themselves -- learning the lessons of history as they should . \n",
       " \n",
       "  xxmaj such insights are precisely what societies still need -- and not just the remaining illiterate xxmaj latinos of xxmaj central and xxmaj south xxmaj america -- yet it 's what xxmaj che(2008 ) xxunk fails to deliver . xxmaj soderbergh xxunk his lead because he 's weak on narrative . i am xxunk why xxmaj xxunk deltoro deliberately chose xxmaj soderbergh for this project if he knew this . xxmaj it 's been xxunk , xxunk about xxmaj xxunk was xxunk wanted : it 's what i went to see this film for , but the director xxunk robs us of that . \n",
       " \n",
       "  xxmaj david xxmaj xxunk , writing in xxmaj the xxmaj australian ( xxunk ) observed that while xxmaj part1 was \" uneven \" , xxmaj part2 actually \" goes rapidly downhill \" from there , \" xxunk xxmaj che 's final xxunk in xxmaj xxunk in xxunk detail \" , which \" ... feels almost unbearably slow and turgid \" . \n",
       " \n",
       "  xxmaj che : xxmaj the xxmaj xxunk aka xxmaj part2 is certainly no xxunk for xxmaj xxunk , painting it a picture of misery and xxunk . xxmaj the entire second half is only xxunk by the aforementioned humour , and the dramatic -- yet tragic -- capture and execution of the film 's subject . \n",
       " \n",
       "  xxmaj the rest of this xxunk cinema xxunk is just confusing , irritating misery -- xxunk , for a xxmaj soderbergh film , to be avoided at all costs . xxmaj it is bound to break the hearts of all who know even just a xxunk about the xxunk / 10 )"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.train.x[434]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuing with Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47875, 0.52125)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y.items==positive).mean(), (y.items==negative).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 6008), (6008,))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.shape, r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (val_term_doc @ r  + b) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.645"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == val_y.items).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, ..., 1, 1, 1, 0])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(low=0,high=2,size=len(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.435"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.random.randint(low=0,high=2,size=len(val_y)) == val_y.items).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "its a start but not that great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching to full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/ricardofernandez/.fastai/data/imdb/test'),\n",
       " PosixPath('/Users/ricardofernandez/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/Users/ricardofernandez/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/Users/ricardofernandez/.fastai/data/imdb/unsup'),\n",
       " PosixPath('/Users/ricardofernandez/.fastai/data/imdb/README'),\n",
       " PosixPath('/Users/ricardofernandez/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/Users/ricardofernandez/.fastai/data/imdb/train')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/ricardofernandez/.fastai/data/imdb/train/neg'),\n",
       " PosixPath('/Users/ricardofernandez/.fastai/data/imdb/train/pos'),\n",
       " PosixPath('/Users/ricardofernandez/.fastai/data/imdb/train/unsupBow.feat'),\n",
       " PosixPath('/Users/ricardofernandez/.fastai/data/imdb/train/labeledBow.feat')]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_full = (TextList.from_folder(path)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos']))\n",
    "             #label them all with their folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_full.train), len(reviews_full.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = reviews_full.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad',\n",
       " 'people',\n",
       " 'will',\n",
       " 'other',\n",
       " 'also',\n",
       " 'into',\n",
       " 'first',\n",
       " 'because',\n",
       " 'great',\n",
       " 'how']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.itos[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.82 s, sys: 155 ms, total: 3.97 s\n",
      "Wall time: 3.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_term_doc = get_term_doc_matrix(reviews_full.valid.x, len(reviews_full.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.89 s, sys: 184 ms, total: 4.07 s\n",
      "Wall time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trn_term_doc = get_term_doc_matrix(reviews_full.train.x, len(reviews_full.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 38456), (25000, 38456))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape, val_term_doc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"trn_term_doc.npz\", trn_term_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"val_term_doc.npz\", val_term_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_term_doc = scipy.sparse.load_npz(\"trn_term_doc.npz\")\n",
    "val_term_doc = scipy.sparse.load_npz(\"val_term_doc.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=trn_term_doc\n",
    "y=reviews_full.train.y\n",
    "\n",
    "val_y = reviews_full.valid.y.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x38456 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3716265 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = y.c2i['pos']\n",
    "negative = y.c2i['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))\n",
    "p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 28450,      0,  12500,      0,      0, 342619,  20464,   1338,      7, 173122, 138000, 143763,  89570,  83404,\n",
       "        76828,  66715,  58510,  47896,  50177,  40451], dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_pos_given_word(word):\n",
    "    print(p0[v.stoi[word]]/p1[v.stoi[word]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.051546391752577\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('hated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6424702058504875\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('liked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3139963167587477\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('loved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48538961038961037\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.837301587301587\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('worst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.log(pr1/pr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7133498878774648"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[v.stoi['hated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1563661500586044"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[v.stoi['loved']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2826243504315076"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[v.stoi['worst']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7225576052173609"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[v.stoi['best']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = y.c2i['neg']\n",
    "p0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))\n",
    "p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)\n",
    "r = np.log(pr1/pr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean()); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (val_term_doc @ r + b) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8084"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3717801, (25000, 38456))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[y.items==negative].sum(), x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / (x[y.items==positive].sum() + x.shape[1])\n",
    "pr0 = (p0+1) / (x[y.items==negative].sum() + x.shape[1])\n",
    "r = np.log(pr1/pr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80376"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (val_term_doc @ r + b) > 0\n",
    "(preds == val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interesting the correct way was not much different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarized Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe it only matters whether a word is in the review or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=trn_term_doc.sign()\n",
    "y=reviews_full.train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1, 0, ..., 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, ..., 1, 0, 0, 1],\n",
       "        [0, 0, 1, 0, ..., 1, 0, 0, 1],\n",
       "        [1, 0, 1, 0, ..., 1, 1, 0, 1],\n",
       "        ...,\n",
       "        [1, 0, 1, 0, ..., 0, 0, 0, 1],\n",
       "        [1, 0, 1, 0, ..., 1, 0, 0, 1],\n",
       "        [0, 0, 1, 0, ..., 1, 0, 0, 1],\n",
       "        [1, 0, 1, 0, ..., 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.todense()[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = y.c2i['neg']\n",
    "positive = y.c2i['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))\n",
    "p0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.log(pr1/pr0)\n",
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean())\n",
    "\n",
    "preds = (val_term_doc.sign() @ r + b) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82924"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88248"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(trn_term_doc, y.items.astype(int))\n",
    "preds = m.predict(val_term_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88536"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(trn_term_doc.sign(), y.items.astype(int))\n",
    "preds = m.predict(val_term_doc.sign())\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram with NB features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stoi[\"xxmaj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxmaj'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.itos[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ab = 99.9/100\n",
    "p_b = 0.01/100\n",
    "p_abc = 0.1/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.083469721767596"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_a = p_ab*p_b + p_abc*(1-p_b)\n",
    "p_ba = p_b * p_ab/p_a\n",
    "p_ba*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.4, 0.8, 0.6000000000000001, 0.20000000000000018)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/5,2/5,4/5,8/5-1,2*(8/5-1)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x<=1/2:\n",
    "        return 2*x\n",
    "    if x>1/2:\n",
    "        return 2*x-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.4\n",
      "0.8\n",
      "0.6000000000000001\n",
      "0.20000000000000018\n"
     ]
    }
   ],
   "source": [
    "x = 1/10\n",
    "for i in range(5):\n",
    "    x = f(x)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
    "                .split_from_df(col=2)\n",
    "                .label_from_df(cols=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = movie_reviews.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create train matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    5, 4619,   25, ...,   10,    5,    0,   52])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.train.x[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([2, 5, 4619, 25, 0, 867, 52, 3776, 1800, 95, 37, 85, 191, 64, 935, 2738, 517, 18, 21, 11, 84, 2417, 192, 88, 3777, 1801, 127, 10, 269, 15, 273, 73, 26, 9, 1360, 35, 1213, 1144, 1145, 2418, 91, 63, 245, 14, 1361, 1447, 65, 40, 796, 103, 72, 99, 534, 616, 48, 282, 54, 90, 219, 228, 43, 13, 3778, 3779, 355, 492])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(movie_reviews.train.x[0].data).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_n = 1\n",
    "max_n = 3\n",
    "\n",
    "j_indices = []\n",
    "indptr = []\n",
    "values = []\n",
    "indptr.append(0)\n",
    "num_tokens = vocab_len\n",
    "\n",
    "itongram = dict()\n",
    "ngramtoi = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramtoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(movie_reviews.train.x):\n",
    "    feature_counter = Counter(doc.data)\n",
    "    j_indices.extend(feature_counter.keys())\n",
    "    values.extend(feature_counter.values())\n",
    "    this_doc_ngrams = list()\n",
    "\n",
    "    m = 0\n",
    "    for n in range(min_n, max_n + 1):\n",
    "        for k in range(vocab_len - n + 1):\n",
    "            ngram = doc.data[k: k + n]\n",
    "            if str(ngram) not in ngramtoi:\n",
    "                if len(ngram)==1:\n",
    "                    num = ngram[0]\n",
    "                    ngramtoi[str(ngram)] = num\n",
    "                    itongram[num] = ngram\n",
    "                else:\n",
    "                    ngramtoi[str(ngram)] = num_tokens\n",
    "                    itongram[num_tokens] = ngram\n",
    "                    num_tokens += 1\n",
    "            this_doc_ngrams.append(ngramtoi[str(ngram)])\n",
    "            m += 1\n",
    "\n",
    "    ngram_counter = Counter(this_doc_ngrams)\n",
    "    j_indices.extend(ngram_counter.keys())\n",
    "    values.extend(ngram_counter.values())\n",
    "    indptr.append(len(j_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram_doc_matrix = scipy.sparse.csr_matrix((values, j_indices, indptr),\n",
    "                                   shape=(len(indptr) - 1, len(ngramtoi)),\n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260374, 260374)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngramtoi), len(itongram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15,   9, 710])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itongram[20005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20005"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramtoi[str(np.array([15,9,710]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1140,   33])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itongram[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hate', 'you')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[1140], v[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create valid matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_indices = []\n",
    "indptr = []\n",
    "values = []\n",
    "indptr.append(0)\n",
    "\n",
    "for i, doc in enumerate(movie_reviews.valid.x):\n",
    "    feature_counter = Counter(doc.data)\n",
    "    j_indices.extend(feature_counter.keys())\n",
    "    values.extend(feature_counter.values())\n",
    "    this_doc_ngrams = list()\n",
    "\n",
    "    m = 0\n",
    "    for n in range(min_n, max_n + 1):\n",
    "        for k in range(vocab_len - n + 1):\n",
    "            ngram = doc.data[k: k + n]\n",
    "            if str(ngram) in ngramtoi:\n",
    "                this_doc_ngrams.append(ngramtoi[str(ngram)])\n",
    "            m += 1\n",
    "\n",
    "    ngram_counter = Counter(this_doc_ngrams)\n",
    "    j_indices.extend(ngram_counter.keys())\n",
    "    values.extend(ngram_counter.values())\n",
    "    indptr.append(len(j_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ngram_doc_matrix = scipy.sparse.csr_matrix((values, j_indices, indptr),\n",
    "                                   shape=(len(indptr) - 1, len(ngramtoi)),\n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200x260374 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 121600 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x260374 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 678951 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_doc_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"train_ngram_matrix.npz\", train_ngram_doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"valid_ngram_matrix.npz\", valid_ngram_doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('itongram.pickle', 'wb') as handle:\n",
    "    pickle.dump(itongram, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ngramtoi.pickle', 'wb') as handle:\n",
    "    pickle.dump(itongram, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram_doc_matrix = scipy.sparse.load_npz(\"train_ngram_matrix.npz\")\n",
    "valid_ngram_doc_matrix = scipy.sparse.load_npz(\"valid_ngram_matrix.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('itongram.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "    \n",
    "with open('ngramtoi.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train_ngram_doc_matrix\n",
    "y=movie_reviews.train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = y.c2i[\"positive\"]\n",
    "negative = y.c2i['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x260374 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 678951 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260374"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = x.shape[1]; k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = (y.items == positive)[:k]\n",
    "neg = (y.items == negative)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = x[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = [o == positive for o in movie_reviews.valid.y.items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.squeeze(np.array(xx[neg].sum(0)))\n",
    "p1 = np.squeeze(np.array(xx[pos].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.log(pr1/pr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08505123261815539"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47875, 0.52125)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y.items==positive).mean(), (y.items==negative).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260374,)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_preds = valid_ngram_doc_matrix @ r.T + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pre_preds.T > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False,  True,  True, False,  True, False])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = [o == positive for o in movie_reviews.valid.y.items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == valid_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "better result then only using unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarized Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_x_ngram_sgn = train_ngram_doc_matrix.sign()\n",
    "val_x_ngram_sgn = valid_ngram_doc_matrix.sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = trn_x_ngram_sgn[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 260374), (800, 260374))"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_x_ngram_sgn.shape, xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.squeeze(np.array(xx[neg].sum(0)))\n",
    "p1 = np.squeeze(np.array(xx[pos].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.log(pr1/pr0)\n",
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean())\n",
    "\n",
    "pre_preds = val_x_ngram_sgn @ r.T + b\n",
    "preds = pre_preds.T>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logisitic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use CountVectorizer to compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "??noop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr = CountVectorizer(ngram_range=(1,3), preprocessor=noop,\n",
    "                        tokenizer=noop, max_features=800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = movie_reviews.train.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = [[docs.vocab.itos[o] for o in doc.data] for doc in movie_reviews.train.x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxbos',\n",
       " 'xxmaj',\n",
       " 'un',\n",
       " '-',\n",
       " 'xxunk',\n",
       " '-',\n",
       " 'believable',\n",
       " '!',\n",
       " 'xxmaj',\n",
       " 'meg',\n",
       " 'xxmaj',\n",
       " 'ryan',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'even',\n",
       " 'look',\n",
       " 'her',\n",
       " 'usual',\n",
       " 'xxunk',\n",
       " 'lovable',\n",
       " 'self',\n",
       " 'in',\n",
       " 'this',\n",
       " ',',\n",
       " 'which',\n",
       " 'normally',\n",
       " 'makes',\n",
       " 'me',\n",
       " 'forgive',\n",
       " 'her',\n",
       " 'shallow',\n",
       " 'xxunk',\n",
       " 'acting',\n",
       " 'xxunk',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'believe',\n",
       " 'she',\n",
       " 'was',\n",
       " 'the',\n",
       " 'producer',\n",
       " 'on',\n",
       " 'this',\n",
       " 'dog',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'plus',\n",
       " 'xxmaj',\n",
       " 'kevin',\n",
       " 'xxmaj',\n",
       " 'kline',\n",
       " ':',\n",
       " 'what',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'suicide',\n",
       " 'trip',\n",
       " 'has',\n",
       " 'his',\n",
       " 'career',\n",
       " 'been',\n",
       " 'on',\n",
       " '?',\n",
       " 'xxmaj',\n",
       " 'xxunk',\n",
       " '...',\n",
       " 'xxmaj',\n",
       " 'xxunk',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " 'xxmaj',\n",
       " 'finally',\n",
       " 'this',\n",
       " 'was',\n",
       " 'directed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'guy',\n",
       " 'who',\n",
       " 'did',\n",
       " 'xxmaj',\n",
       " 'big',\n",
       " 'xxmaj',\n",
       " 'xxunk',\n",
       " '?',\n",
       " 'xxmaj',\n",
       " 'must',\n",
       " 'be',\n",
       " 'a',\n",
       " 'replay',\n",
       " 'of',\n",
       " 'xxmaj',\n",
       " 'jonestown',\n",
       " '-',\n",
       " 'hollywood',\n",
       " 'style',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'xxunk',\n",
       " '!']"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_words = [[docs.vocab.itos[o] for o in doc.data] for doc in movie_reviews.valid.x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "463\n",
      "220\n",
      "185\n",
      "397\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(train_words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.44 s, sys: 69.5 ms, total: 1.51 s\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_ngram_doc = veczr.fit_transform(train_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x260373 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 565680 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xxbos': 235215,\n",
       " 'xxmaj': 235589,\n",
       " 'un': 217511,\n",
       " '-': 14660,\n",
       " 'xxunk': 247952,\n",
       " 'believable': 50420,\n",
       " '!': 593,\n",
       " 'meg': 134438,\n",
       " 'ryan': 171955,\n",
       " 'does': 72621,\n",
       " \"n't\": 141191,\n",
       " 'even': 78281,\n",
       " 'look': 129009,\n",
       " 'her': 101674,\n",
       " 'usual': 219401,\n",
       " 'lovable': 129862,\n",
       " 'self': 175864,\n",
       " 'in': 110056,\n",
       " 'this': 206619,\n",
       " ',': 8800,\n",
       " 'which': 228198,\n",
       " 'normally': 145182,\n",
       " 'makes': 131546,\n",
       " 'me': 133646,\n",
       " 'forgive': 88662,\n",
       " 'shallow': 177158,\n",
       " 'acting': 27682,\n",
       " '.': 16836,\n",
       " 'hard': 97855,\n",
       " 'to': 210364,\n",
       " 'believe': 50457,\n",
       " 'she': 177306,\n",
       " 'was': 222309,\n",
       " 'the': 193798,\n",
       " 'producer': 164483,\n",
       " 'on': 152319,\n",
       " 'dog': 72926,\n",
       " 'plus': 162127,\n",
       " 'kevin': 122604,\n",
       " 'kline': 123461,\n",
       " ':': 20359,\n",
       " 'what': 226855,\n",
       " 'kind': 123231,\n",
       " 'of': 147512,\n",
       " 'suicide': 188353,\n",
       " 'trip': 215808,\n",
       " 'has': 98123,\n",
       " 'his': 103526,\n",
       " 'career': 58691,\n",
       " 'been': 49234,\n",
       " '?': 20987,\n",
       " '...': 18342,\n",
       " 'finally': 85368,\n",
       " 'directed': 71212,\n",
       " 'by': 56556,\n",
       " 'guy': 96410,\n",
       " 'who': 229023,\n",
       " 'did': 70468,\n",
       " 'big': 51595,\n",
       " 'must': 140407,\n",
       " 'be': 47412,\n",
       " 'a': 21275,\n",
       " 'replay': 169611,\n",
       " 'jonestown': 121174,\n",
       " 'hollywood': 105183,\n",
       " 'style': 187604,\n",
       " 'xxbos xxmaj': 235357,\n",
       " 'xxmaj un': 246383,\n",
       " 'un -': 217512,\n",
       " '- xxunk': 16422,\n",
       " 'xxunk -': 248697,\n",
       " '- believable': 14848,\n",
       " 'believable !': 50421,\n",
       " '! xxmaj': 756,\n",
       " 'xxmaj meg': 242183,\n",
       " 'meg xxmaj': 134443,\n",
       " 'xxmaj ryan': 244138,\n",
       " 'ryan does': 171964,\n",
       " \"does n't\": 72753,\n",
       " \"n't even\": 141520,\n",
       " 'even look': 78521,\n",
       " 'look her': 129094,\n",
       " 'her usual': 102320,\n",
       " 'usual xxunk': 219433,\n",
       " 'xxunk lovable': 252438,\n",
       " 'lovable self': 129871,\n",
       " 'self in': 175889,\n",
       " 'in this': 111780,\n",
       " 'this ,': 206638,\n",
       " ', which': 13810,\n",
       " 'which normally': 228470,\n",
       " 'normally makes': 145185,\n",
       " 'makes me': 131625,\n",
       " 'me forgive': 133781,\n",
       " 'forgive her': 88663,\n",
       " 'her shallow': 102226,\n",
       " 'shallow xxunk': 177173,\n",
       " 'xxunk acting': 249119,\n",
       " 'acting xxunk': 27924,\n",
       " 'xxunk .': 248797,\n",
       " '. xxmaj': 17369,\n",
       " 'xxmaj hard': 239904,\n",
       " 'hard to': 97911,\n",
       " 'to believe': 210897,\n",
       " 'believe she': 50526,\n",
       " 'she was': 177750,\n",
       " 'was the': 223683,\n",
       " 'the producer': 199538,\n",
       " 'producer on': 164495,\n",
       " 'on this': 153091,\n",
       " 'this dog': 206958,\n",
       " 'dog .': 72927,\n",
       " 'xxmaj plus': 243513,\n",
       " 'plus xxmaj': 162147,\n",
       " 'xxmaj kevin': 241336,\n",
       " 'kevin xxmaj': 122609,\n",
       " 'xxmaj kline': 241432,\n",
       " 'kline :': 123467,\n",
       " ': what': 20589,\n",
       " 'what kind': 227108,\n",
       " 'kind of': 123254,\n",
       " 'of suicide': 149874,\n",
       " 'suicide trip': 188375,\n",
       " 'trip has': 215819,\n",
       " 'has his': 98393,\n",
       " 'his career': 103704,\n",
       " 'career been': 58707,\n",
       " 'been on': 49445,\n",
       " 'on ?': 152368,\n",
       " '? xxmaj': 21111,\n",
       " 'xxmaj xxunk': 247309,\n",
       " 'xxunk ...': 248843,\n",
       " '... xxmaj': 18626,\n",
       " 'xxunk !': 247957,\n",
       " '! !': 608,\n",
       " 'xxmaj finally': 239054,\n",
       " 'finally this': 85430,\n",
       " 'this was': 208162,\n",
       " 'was directed': 222764,\n",
       " 'directed by': 71225,\n",
       " 'by the': 56975,\n",
       " 'the guy': 197076,\n",
       " 'guy who': 96501,\n",
       " 'who did': 229220,\n",
       " 'did xxmaj': 70743,\n",
       " 'xxmaj big': 236722,\n",
       " 'big xxmaj': 51745,\n",
       " 'xxunk ?': 248967,\n",
       " 'xxmaj must': 242513,\n",
       " 'must be': 140420,\n",
       " 'be a': 47457,\n",
       " 'a replay': 24646,\n",
       " 'replay of': 169614,\n",
       " 'of xxmaj': 150909,\n",
       " 'xxmaj jonestown': 241138,\n",
       " 'jonestown -': 121175,\n",
       " '- hollywood': 15339,\n",
       " 'hollywood style': 105256,\n",
       " 'style .': 187615,\n",
       " 'xxbos xxmaj un': 235543,\n",
       " 'xxmaj un -': 246384,\n",
       " 'un - xxunk': 217515,\n",
       " '- xxunk -': 16428,\n",
       " 'xxunk - believable': 248707,\n",
       " '- believable !': 14849,\n",
       " 'believable ! xxmaj': 50422,\n",
       " '! xxmaj meg': 813,\n",
       " 'xxmaj meg xxmaj': 242186,\n",
       " 'meg xxmaj ryan': 134445,\n",
       " 'xxmaj ryan does': 244143,\n",
       " \"ryan does n't\": 171965,\n",
       " \"does n't even\": 72768,\n",
       " \"n't even look\": 141536,\n",
       " 'even look her': 78523,\n",
       " 'look her usual': 129095,\n",
       " 'her usual xxunk': 102322,\n",
       " 'usual xxunk lovable': 219436,\n",
       " 'xxunk lovable self': 252439,\n",
       " 'lovable self in': 129872,\n",
       " 'self in this': 175890,\n",
       " 'in this ,': 111782,\n",
       " 'this , which': 206664,\n",
       " ', which normally': 13842,\n",
       " 'which normally makes': 228471,\n",
       " 'normally makes me': 145186,\n",
       " 'makes me forgive': 131629,\n",
       " 'me forgive her': 133782,\n",
       " 'forgive her shallow': 88664,\n",
       " 'her shallow xxunk': 102227,\n",
       " 'shallow xxunk acting': 177174,\n",
       " 'xxunk acting xxunk': 249121,\n",
       " 'acting xxunk .': 27925,\n",
       " 'xxunk . xxmaj': 248831,\n",
       " '. xxmaj hard': 17667,\n",
       " 'xxmaj hard to': 239905,\n",
       " 'hard to believe': 97918,\n",
       " 'to believe she': 210904,\n",
       " 'believe she was': 50527,\n",
       " 'she was the': 177783,\n",
       " 'was the producer': 223725,\n",
       " 'the producer on': 199540,\n",
       " 'producer on this': 164496,\n",
       " 'on this dog': 153096,\n",
       " 'this dog .': 206959,\n",
       " 'dog . xxmaj': 72929,\n",
       " '. xxmaj plus': 17911,\n",
       " 'xxmaj plus xxmaj': 243517,\n",
       " 'plus xxmaj kevin': 162150,\n",
       " 'xxmaj kevin xxmaj': 241339,\n",
       " 'kevin xxmaj kline': 122611,\n",
       " 'xxmaj kline :': 241435,\n",
       " 'kline : what': 123468,\n",
       " ': what kind': 20590,\n",
       " 'what kind of': 227109,\n",
       " 'kind of suicide': 123303,\n",
       " 'of suicide trip': 149876,\n",
       " 'suicide trip has': 188376,\n",
       " 'trip has his': 215820,\n",
       " 'has his career': 98395,\n",
       " 'his career been': 103708,\n",
       " 'career been on': 58708,\n",
       " 'been on ?': 49446,\n",
       " 'on ? xxmaj': 152369,\n",
       " '? xxmaj xxunk': 21210,\n",
       " 'xxmaj xxunk ...': 247323,\n",
       " 'xxunk ... xxmaj': 248862,\n",
       " '... xxmaj xxunk': 18661,\n",
       " 'xxmaj xxunk !': 247310,\n",
       " 'xxunk ! !': 247959,\n",
       " '! ! !': 610,\n",
       " '! ! xxmaj': 615,\n",
       " '! xxmaj finally': 793,\n",
       " 'xxmaj finally this': 239059,\n",
       " 'finally this was': 85431,\n",
       " 'this was directed': 208170,\n",
       " 'was directed by': 222765,\n",
       " 'directed by the': 71226,\n",
       " 'by the guy': 57017,\n",
       " 'the guy who': 197081,\n",
       " 'guy who did': 96505,\n",
       " 'who did xxmaj': 229223,\n",
       " 'did xxmaj big': 70745,\n",
       " 'xxmaj big xxmaj': 236727,\n",
       " 'big xxmaj xxunk': 51752,\n",
       " 'xxmaj xxunk ?': 247337,\n",
       " 'xxunk ? xxmaj': 248978,\n",
       " '? xxmaj must': 21162,\n",
       " 'xxmaj must be': 242514,\n",
       " 'must be a': 140422,\n",
       " 'be a replay': 47502,\n",
       " 'a replay of': 24647,\n",
       " 'replay of xxmaj': 169616,\n",
       " 'of xxmaj jonestown': 151052,\n",
       " 'xxmaj jonestown -': 241139,\n",
       " 'jonestown - hollywood': 121176,\n",
       " '- hollywood style': 15340,\n",
       " 'hollywood style .': 105257,\n",
       " 'style . xxmaj': 187616,\n",
       " '. xxmaj xxunk': 18188,\n",
       " 'is': 114366,\n",
       " 'extremely': 80761,\n",
       " 'well': 225716,\n",
       " 'made': 130644,\n",
       " 'film': 83820,\n",
       " 'script': 174274,\n",
       " 'and': 33946,\n",
       " 'camera': 57721,\n",
       " 'work': 233483,\n",
       " 'are': 41012,\n",
       " 'all': 30461,\n",
       " 'first': 85890,\n",
       " 'rate': 166609,\n",
       " 'music': 140241,\n",
       " 'good': 94145,\n",
       " 'too': 214407,\n",
       " 'though': 208610,\n",
       " 'it': 117551,\n",
       " 'mostly': 137844,\n",
       " 'early': 74979,\n",
       " 'when': 227457,\n",
       " 'things': 206075,\n",
       " 'still': 185848,\n",
       " 'relatively': 168961,\n",
       " 'there': 204250,\n",
       " 'no': 144363,\n",
       " 'really': 167508,\n",
       " 'cast': 59075,\n",
       " 'several': 176859,\n",
       " 'faces': 81047,\n",
       " 'will': 230377,\n",
       " 'familiar': 81626,\n",
       " 'entire': 77477,\n",
       " 'an': 33087,\n",
       " 'excellent': 79796,\n",
       " 'job': 120747,\n",
       " 'with': 231170,\n",
       " '\\n \\n ': 0,\n",
       " 'but': 55216,\n",
       " 'watch': 224112,\n",
       " 'because': 48810,\n",
       " 'end': 76332,\n",
       " 'situation': 180238,\n",
       " 'like': 126902,\n",
       " 'one': 153397,\n",
       " 'presented': 163551,\n",
       " 'now': 146734,\n",
       " 'blame': 52345,\n",
       " 'british': 54342,\n",
       " 'for': 87090,\n",
       " 'setting': 176784,\n",
       " 'hindus': 103470,\n",
       " 'muslims': 140396,\n",
       " 'against': 29861,\n",
       " 'each': 74783,\n",
       " 'other': 156101,\n",
       " 'then': 203872,\n",
       " 'them': 203443,\n",
       " 'into': 113684,\n",
       " 'two': 216847,\n",
       " 'countries': 66006,\n",
       " 'some': 182067,\n",
       " 'merit': 134926,\n",
       " 'view': 220873,\n",
       " \"'s\": 4211,\n",
       " 'also': 31789,\n",
       " 'true': 215922,\n",
       " 'that': 191516,\n",
       " 'forced': 88464,\n",
       " 'region': 168789,\n",
       " 'as': 42798,\n",
       " 'they': 204938,\n",
       " 'around': 42440,\n",
       " 'time': 209681,\n",
       " 'partition': 158797,\n",
       " 'seems': 175459,\n",
       " 'more': 136835,\n",
       " 'likely': 127636,\n",
       " 'simply': 179651,\n",
       " 'saw': 172784,\n",
       " 'between': 51328,\n",
       " 'were': 226122,\n",
       " 'clever': 62384,\n",
       " 'enough': 77130,\n",
       " 'exploit': 80552,\n",
       " 'their': 202830,\n",
       " 'own': 157760,\n",
       " 'ends': 76690,\n",
       " 'result': 169915,\n",
       " 'much': 139717,\n",
       " 'cruelty': 67238,\n",
       " 'inhumanity': 112819,\n",
       " 'very': 219998,\n",
       " 'unpleasant': 218249,\n",
       " 'remember': 169283,\n",
       " 'see': 174814,\n",
       " 'screen': 174075,\n",
       " 'never': 143353,\n",
       " 'painted': 158224,\n",
       " 'black': 52194,\n",
       " 'white': 228937,\n",
       " 'case': 58970,\n",
       " 'both': 53375,\n",
       " 'sides': 179375,\n",
       " 'hope': 105512,\n",
       " 'change': 59918,\n",
       " 'younger': 259666,\n",
       " 'generation': 91755,\n",
       " 'redemption': 168583,\n",
       " 'sort': 183596,\n",
       " 'make': 131230,\n",
       " 'choice': 61337,\n",
       " 'man': 131946,\n",
       " 'ruined': 171644,\n",
       " 'life': 126517,\n",
       " 'truly': 216065,\n",
       " 'loved': 130082,\n",
       " 'family': 81657,\n",
       " 'later': 124768,\n",
       " 'come': 63097,\n",
       " 'looking': 129227,\n",
       " 'point': 162183,\n",
       " 'without': 232553,\n",
       " 'great': 95354,\n",
       " 'pain': 158128,\n",
       " 'carries': 58854,\n",
       " 'message': 134989,\n",
       " 'have': 98825,\n",
       " 'grave': 95320,\n",
       " 'can': 57887,\n",
       " 'caring': 58767,\n",
       " 'people': 159376,\n",
       " 'reality': 167409,\n",
       " 'wrenching': 234800,\n",
       " 'since': 179821,\n",
       " 'real': 167120,\n",
       " 'across': 27566,\n",
       " 'india': 112483,\n",
       " '/': 18685,\n",
       " 'pakistan': 158273,\n",
       " 'border': 53135,\n",
       " 'sense': 175979,\n",
       " 'similar': 179525,\n",
       " '\"': 885,\n",
       " 'mr': 139630,\n",
       " '&': 2764,\n",
       " 'we': 225002,\n",
       " 'glad': 93381,\n",
       " 'seen': 175586,\n",
       " 'resolution': 169763,\n",
       " 'if': 109091,\n",
       " 'xxup': 256420,\n",
       " 'uk': 217428,\n",
       " 'us': 218989,\n",
       " 'could': 65629,\n",
       " 'deal': 68601,\n",
       " 'racism': 166226,\n",
       " 'would': 234302,\n",
       " 'certainly': 59722,\n",
       " 'better': 51084,\n",
       " 'off': 151359,\n",
       " 'xxmaj this': 245963,\n",
       " 'this is': 207315,\n",
       " 'is a': 114454,\n",
       " 'a extremely': 22460,\n",
       " 'extremely well': 80814,\n",
       " 'well -': 225761,\n",
       " '- made': 15548,\n",
       " 'made film': 130753,\n",
       " 'film .': 83976,\n",
       " 'xxmaj the': 245396,\n",
       " 'the acting': 194047,\n",
       " 'acting ,': 27699,\n",
       " ', script': 12374,\n",
       " 'script and': 174304,\n",
       " 'and camera': 34620,\n",
       " 'camera -': 57732,\n",
       " '- work': 16324,\n",
       " 'work are': 233518,\n",
       " 'are all': 41095,\n",
       " 'all first': 30706,\n",
       " 'first -': 85912,\n",
       " '- rate': 15849,\n",
       " 'rate .': 166614,\n",
       " 'the music': 198546,\n",
       " 'music is': 140305,\n",
       " 'is good': 115451,\n",
       " 'good ,': 94164,\n",
       " ', too': 13451,\n",
       " 'too ,': 214410,\n",
       " ', though': 13364,\n",
       " 'though it': 208705,\n",
       " 'it is': 118571,\n",
       " 'is mostly': 115889,\n",
       " 'mostly early': 137871,\n",
       " 'early in': 75023,\n",
       " 'in the': 111407,\n",
       " 'the film': 196370,\n",
       " 'film ,': 83895,\n",
       " ', when': 13757,\n",
       " 'when things': 227777,\n",
       " 'things are': 206105,\n",
       " 'are still': 41990,\n",
       " 'still relatively': 186037,\n",
       " 'relatively xxunk': 168972,\n",
       " 'xxmaj there': 245855,\n",
       " 'there are': 204333,\n",
       " 'are no': 41690,\n",
       " 'no really': 144751,\n",
       " 'really xxunk': 168047,\n",
       " 'xxunk in': 251851,\n",
       " 'the cast': 194866,\n",
       " 'cast ,': 59084,\n",
       " 'though several': 208725,\n",
       " 'several faces': 176868,\n",
       " 'faces will': 81063,\n",
       " 'will be': 230412,\n",
       " 'be familiar': 47777,\n",
       " 'familiar .': 81630,\n",
       " 'the entire': 196050,\n",
       " 'entire cast': 77482,\n",
       " 'cast does': 59134,\n",
       " 'does an': 72651,\n",
       " 'an excellent': 33466,\n",
       " 'excellent job': 79841,\n",
       " 'job with': 120821,\n",
       " 'with the': 232077,\n",
       " 'the script': 200171,\n",
       " 'script .': 174296,\n",
       " '. \\n \\n ': 16837,\n",
       " '\\n \\n  xxmaj': 201,\n",
       " 'xxmaj but': 237126,\n",
       " 'but it': 55695,\n",
       " 'is hard': 115484,\n",
       " 'to watch': 213667,\n",
       " 'watch ,': 224118,\n",
       " ', because': 9675,\n",
       " 'because there': 48980,\n",
       " 'there is': 204441,\n",
       " 'is no': 116005,\n",
       " 'no good': 144551,\n",
       " 'good end': 94326,\n",
       " 'end to': 76473,\n",
       " 'to a': 210430,\n",
       " 'a situation': 24996,\n",
       " 'situation like': 180259,\n",
       " 'like the': 127322,\n",
       " 'the one': 198830,\n",
       " 'one presented': 153897,\n",
       " 'presented .': 163554,\n",
       " 'xxmaj it': 240727,\n",
       " 'is now': 116121,\n",
       " 'now xxunk': 146917,\n",
       " 'xxunk to': 254850,\n",
       " 'to blame': 210923,\n",
       " 'blame the': 52354,\n",
       " 'the xxmaj': 201947,\n",
       " 'xxmaj british': 236999,\n",
       " 'british for': 54363,\n",
       " 'for setting': 87889,\n",
       " 'setting xxmaj': 176810,\n",
       " 'xxmaj hindus': 240185,\n",
       " 'hindus and': 103471,\n",
       " 'and xxmaj': 38613,\n",
       " 'xxmaj muslims': 242508,\n",
       " 'muslims against': 140400,\n",
       " 'against each': 29874,\n",
       " 'each other': 74849,\n",
       " 'other ,': 156112,\n",
       " ', and': 9210,\n",
       " 'and then': 37926,\n",
       " 'then xxunk': 204208,\n",
       " 'xxunk xxunk': 256113,\n",
       " 'xxunk them': 254689,\n",
       " 'them into': 203601,\n",
       " 'into two': 114005,\n",
       " 'two countries': 216919,\n",
       " 'countries .': 66007,\n",
       " 'is some': 116649,\n",
       " 'some merit': 182377,\n",
       " 'merit in': 134929,\n",
       " 'this view': 208150,\n",
       " 'view ,': 220878,\n",
       " ', but': 9816,\n",
       " \"it 's\": 117588,\n",
       " \"'s also\": 4421,\n",
       " 'also true': 32183,\n",
       " 'true that': 216022,\n",
       " 'that no': 192771,\n",
       " 'no one': 144674,\n",
       " 'one forced': 153656,\n",
       " 'forced xxmaj': 88496,\n",
       " 'muslims in': 140404,\n",
       " 'the region': 199760,\n",
       " 'region to': 168794,\n",
       " 'to xxunk': 213906,\n",
       " 'xxunk each': 250833,\n",
       " 'other as': 156152,\n",
       " 'as they': 43777,\n",
       " 'they did': 205222,\n",
       " 'did around': 70505,\n",
       " 'around the': 42544,\n",
       " 'the time': 201139,\n",
       " 'time of': 209909,\n",
       " 'of partition': 149424,\n",
       " 'partition .': 158798,\n",
       " 'it seems': 119090,\n",
       " 'seems more': 175506,\n",
       " 'more likely': 137145,\n",
       " 'likely that': 127641,\n",
       " 'that the': 193156,\n",
       " 'british simply': 54371,\n",
       " 'simply saw': 179762,\n",
       " 'saw the': 172841,\n",
       " 'the xxunk': 202328,\n",
       " 'xxunk between': 250006,\n",
       " 'between the': 51405,\n",
       " 'xxunk and': 249286,\n",
       " 'and were': 38443,\n",
       " 'were clever': 226238,\n",
       " 'clever enough': 62404,\n",
       " 'enough to': 77231,\n",
       " 'to exploit': 211447,\n",
       " 'exploit them': 80555,\n",
       " 'them to': 203679,\n",
       " 'to their': 213475,\n",
       " 'their own': 203196,\n",
       " 'own ends': 157823,\n",
       " 'ends .': 76695,\n",
       " 'the result': 199836,\n",
       " 'result is': 169924,\n",
       " 'is that': 116796,\n",
       " 'that there': 193275,\n",
       " 'is much': 115900,\n",
       " 'much cruelty': 139809,\n",
       " 'cruelty and': 67241,\n",
       " 'and inhumanity': 35995,\n",
       " 'inhumanity in': 112822,\n",
       " 'the situation': 200461,\n",
       " 'situation and': 180247,\n",
       " 'and this': 38036,\n",
       " 'is very': 117137,\n",
       " 'very unpleasant': 220509,\n",
       " 'unpleasant to': 218256,\n",
       " 'to remember': 212696,\n",
       " 'remember and': 169296,\n",
       " 'and to': 38111,\n",
       " 'to see': 212854,\n",
       " 'see on': 175040,\n",
       " 'on the': 152902,\n",
       " 'the screen': 200136,\n",
       " 'screen .': 174091,\n",
       " 'is never': 115991,\n",
       " 'never painted': 143568,\n",
       " 'painted as': 158229,\n",
       " 'as a': 42823,\n",
       " 'a black': 21626,\n",
       " 'black -': 52203,\n",
       " '- and': 14760,\n",
       " 'and -': 33996,\n",
       " '- white': 16291,\n",
       " 'white case': 228952,\n",
       " 'case .': 58987,\n",
       " 'is xxunk': 117365,\n",
       " 'and xxunk': 38888,\n",
       " 'xxunk on': 253072,\n",
       " 'on both': 152517,\n",
       " 'both sides': 53502,\n",
       " 'sides ,': 179376,\n",
       " 'and also': 34248,\n",
       " 'also the': 32154,\n",
       " 'the hope': 197241,\n",
       " 'hope for': 105530,\n",
       " 'for change': 87359,\n",
       " 'change in': 59935,\n",
       " 'the younger': 202749,\n",
       " 'younger generation': 259673,\n",
       " 'generation .': 91761,\n",
       " 'is redemption': 116416,\n",
       " 'redemption of': 168590,\n",
       " 'of a': 147610,\n",
       " 'a sort': 25099,\n",
       " 'sort ,': 183597,\n",
       " ', in': 11120,\n",
       " 'the end': 195972,\n",
       " 'end ,': 76339,\n",
       " 'when xxmaj': 227801,\n",
       " 'xxunk has': 251511,\n",
       " 'has to': 98634,\n",
       " 'to make': 212189,\n",
       " 'make a': 131241,\n",
       " 'a hard': 23137,\n",
       " 'hard choice': 97881,\n",
       " 'choice between': 61345,\n",
       " 'between a': 51341,\n",
       " 'a man': 23685,\n",
       " 'man who': 132150,\n",
       " 'who has': 229325,\n",
       " 'has ruined': 98557,\n",
       " 'ruined her': 171652,\n",
       " 'her life': 102060,\n",
       " 'life ,': 126534,\n",
       " 'but also': 55298,\n",
       " 'also truly': 32185,\n",
       " 'truly loved': 216110,\n",
       " 'loved her': 130091,\n",
       " 'her ,': 101692,\n",
       " 'and her': 35712,\n",
       " 'her family': 101932,\n",
       " 'family which': 81804,\n",
       " 'which has': 228319,\n",
       " 'has xxunk': 98680,\n",
       " 'xxunk her': 251582,\n",
       " ', then': 13173,\n",
       " 'then later': 204072,\n",
       " 'later come': 124810,\n",
       " 'come looking': 63158,\n",
       " 'looking for': 129260,\n",
       " 'for her': 87496,\n",
       " 'her .': 101710,\n",
       " 'but by': 55370,\n",
       " 'by that': 56972,\n",
       " 'that point': 192893,\n",
       " 'point ,': 162186,\n",
       " ', she': 12445,\n",
       " 'she has': 177504,\n",
       " 'has no': 98482,\n",
       " 'no xxunk': 144880,\n",
       " 'xxunk that': 254369,\n",
       " 'that is': 192435,\n",
       " 'is without': 117270,\n",
       " 'without great': 232630,\n",
       " 'great pain': 95591,\n",
       " 'pain for': 158144,\n",
       " 'this film': 207025,\n",
       " 'film carries': 84143,\n",
       " 'carries the': 58858,\n",
       " 'the message': 198158,\n",
       " 'message that': 135026,\n",
       " 'that both': 191862,\n",
       " 'both xxmaj': 53538,\n",
       " 'muslims and': 140402,\n",
       " 'hindus have': 103473,\n",
       " 'have their': 99557,\n",
       " 'their grave': 203063,\n",
       " 'grave xxunk': 95335,\n",
       " 'xxunk ,': 248396,\n",
       " 'also that': 32151,\n",
       " 'both can': 53406,\n",
       " 'can be': 57938,\n",
       " 'be xxunk': 48415,\n",
       " 'and caring': 34640,\n",
       " 'caring people': 58777,\n",
       " 'people .': 159412,\n",
       " 'the reality': 199706,\n",
       " 'reality of': 167436,\n",
       " 'partition makes': 158802,\n",
       " 'makes that': 131661,\n",
       " 'that xxunk': 193698,\n",
       " 'xxunk all': 249208,\n",
       " 'all the': 30990,\n",
       " 'the more': 198263,\n",
       " 'more wrenching': 137388,\n",
       " 'wrenching ,': 234801,\n",
       " ', since': 12528,\n",
       " 'since there': 179899,\n",
       " 'there can': 204406,\n",
       " 'can never': 58108,\n",
       " 'never be': 143375,\n",
       " 'be real': 48100,\n",
       " 'real xxunk': 167321,\n",
       " 'xxunk across': 249113,\n",
       " 'across the': 27586,\n",
       " 'xxmaj india': 240590,\n",
       " 'india /': 112490,\n",
       " '/ xxmaj': 18907,\n",
       " 'xxmaj pakistan': 243182,\n",
       " 'pakistan border': 158276,\n",
       " 'border .': 53138,\n",
       " 'xxmaj in': 240533,\n",
       " 'in that': 111376,\n",
       " 'that sense': 193016,\n",
       " 'sense ,': 175985,\n",
       " ', it': 11287,\n",
       " 'is similar': 116578,\n",
       " 'similar to': 179557,\n",
       " 'to \"': 210368,\n",
       " '\" xxmaj': 2328,\n",
       " 'xxmaj mr': 242460,\n",
       " 'mr &': 139631,\n",
       " '& xxmaj': 2903,\n",
       " 'xxunk xxmaj': 255664,\n",
       " 'xxunk \"': 247972,\n",
       " '\" .': 1004,\n",
       " ', we': 13678,\n",
       " 'we were': 225329,\n",
       " 'were glad': 226337,\n",
       " 'glad to': 93394,\n",
       " 'to have': 211733,\n",
       " 'have seen': 99432,\n",
       " 'seen the': 175774,\n",
       " ', even': 10426,\n",
       " 'even though': 78667,\n",
       " 'though the': 208736,\n",
       " 'the resolution': 199820,\n",
       " 'resolution was': 169779,\n",
       " 'was xxunk': 223942,\n",
       " 'xxmaj if': 240474,\n",
       " 'if the': 109289,\n",
       " 'the xxup': 202653,\n",
       " 'xxup uk': 257596,\n",
       " 'uk and': 217435,\n",
       " 'and xxup': 39047,\n",
       " 'xxup us': 257609,\n",
       " 'us could': 219041,\n",
       " 'could deal': 65715,\n",
       " 'deal with': 68620,\n",
       " 'with their': 232212,\n",
       " 'own xxunk': 157951,\n",
       " 'xxunk of': 252885,\n",
       " 'of racism': 149553,\n",
       " 'racism with': 166246,\n",
       " 'with this': 232244,\n",
       " 'this kind': 207417,\n",
       " 'of xxunk': 151175,\n",
       " ', they': 13232,\n",
       " 'they would': 205812,\n",
       " 'would certainly': 234409,\n",
       " 'certainly be': 59727,\n",
       " 'be better': 47628,\n",
       " 'better off': 51219,\n",
       " 'off .': 151379,\n",
       " 'xxbos xxmaj this': 235538,\n",
       " 'xxmaj this is': 246003,\n",
       " 'this is a': 207319,\n",
       " 'is a extremely': 114503,\n",
       " 'a extremely well': 22461,\n",
       " 'extremely well -': 80815,\n",
       " 'well - made': 225771,\n",
       " '- made film': 15550,\n",
       " 'made film .': 130755,\n",
       " 'film . xxmaj': 83983,\n",
       " '. xxmaj the': 18069,\n",
       " 'xxmaj the acting': 245406,\n",
       " 'the acting ,': 194049,\n",
       " 'acting , script': 27720,\n",
       " ', script and': 12375,\n",
       " 'script and camera': 174306,\n",
       " 'and camera -': 34621,\n",
       " 'camera - work': 57733,\n",
       " '- work are': 16326,\n",
       " 'work are all': 233519,\n",
       " 'are all first': 41101,\n",
       " 'all first -': 30707,\n",
       " 'first - rate': 85915,\n",
       " '- rate .': 15850,\n",
       " 'rate . xxmaj': 166615,\n",
       " 'xxmaj the music': 245635,\n",
       " 'the music is': 198555,\n",
       " 'music is good': 140308,\n",
       " 'is good ,': 115454,\n",
       " 'good , too': 94181,\n",
       " ', too ,': 13453,\n",
       " 'too , though': 214421,\n",
       " ', though it': 13378,\n",
       " 'though it is': 208709,\n",
       " 'it is mostly': 118641,\n",
       " 'is mostly early': 115894,\n",
       " 'mostly early in': 137872,\n",
       " 'early in the': 75024,\n",
       " 'in the film': 111525,\n",
       " 'the film ,': 196376,\n",
       " 'film , when': 83948,\n",
       " ', when things': 13778,\n",
       " 'when things are': 227778,\n",
       " 'things are still': 206109,\n",
       " 'are still relatively': 41993,\n",
       " 'still relatively xxunk': 186038,\n",
       " 'relatively xxunk .': 168973,\n",
       " '. xxmaj there': 18072,\n",
       " 'xxmaj there are': 245860,\n",
       " 'there are no': 204367,\n",
       " 'are no really': 41701,\n",
       " 'no really xxunk': 144752,\n",
       " 'really xxunk in': 168053,\n",
       " 'xxunk in the': 251923,\n",
       " 'in the cast': 111464,\n",
       " 'the cast ,': 194867,\n",
       " 'cast , though': 59096,\n",
       " ', though several': 13383,\n",
       " 'though several faces': 208726,\n",
       " 'several faces will': 176869,\n",
       " 'faces will be': 81064,\n",
       " 'will be familiar': 230428,\n",
       " 'be familiar .': 47778,\n",
       " 'familiar . xxmaj': 81631,\n",
       " 'xxmaj the entire': 245509,\n",
       " 'the entire cast': 196053,\n",
       " 'entire cast does': 77484,\n",
       " 'cast does an': 59135,\n",
       " 'does an excellent': 72652,\n",
       " 'an excellent job': 33471,\n",
       " 'excellent job with': 79844,\n",
       " 'job with the': 120822,\n",
       " 'with the script': 232189,\n",
       " 'the script .': 200175,\n",
       " 'script . \\n \\n ': 174297,\n",
       " '. \\n \\n  xxmaj': 16871,\n",
       " '\\n \\n  xxmaj but': 256,\n",
       " 'xxmaj but it': 237158,\n",
       " 'but it is': 55712,\n",
       " 'it is hard': 118625,\n",
       " 'is hard to': 115486,\n",
       " 'hard to watch': 97936,\n",
       " 'to watch ,': 213670,\n",
       " 'watch , because': 224119,\n",
       " ', because there': 9688,\n",
       " 'because there is': 48983,\n",
       " 'there is no': 204467,\n",
       " 'is no good': 116014,\n",
       " 'no good end': 144554,\n",
       " 'good end to': 94328,\n",
       " 'end to a': 76474,\n",
       " 'to a situation': 210484,\n",
       " 'a situation like': 24998,\n",
       " 'situation like the': 180260,\n",
       " 'like the one': 127348,\n",
       " 'the one presented': 198845,\n",
       " 'one presented .': 153898,\n",
       " 'presented . xxmaj': 163555,\n",
       " '. xxmaj it': 17714,\n",
       " 'xxmaj it is': 240769,\n",
       " 'it is now': 118650,\n",
       " 'is now xxunk': 116127,\n",
       " 'now xxunk to': 146921,\n",
       " 'xxunk to blame': 254877,\n",
       " 'to blame the': 210925,\n",
       " 'blame the xxmaj': 52357,\n",
       " 'the xxmaj british': 201983,\n",
       " 'xxmaj british for': 237009,\n",
       " 'british for setting': 54364,\n",
       " 'for setting xxmaj': 87890,\n",
       " 'setting xxmaj hindus': 176811,\n",
       " 'xxmaj hindus and': 240186,\n",
       " 'hindus and xxmaj': 103472,\n",
       " 'and xxmaj muslims': 38796,\n",
       " 'xxmaj muslims against': 242510,\n",
       " 'muslims against each': 140401,\n",
       " 'against each other': 29875,\n",
       " 'each other ,': 74851,\n",
       " 'other , and': 156113,\n",
       " ', and then': 9441,\n",
       " 'and then xxunk': 37967,\n",
       " 'then xxunk xxunk': 204219,\n",
       " 'xxunk xxunk them': 256260,\n",
       " 'xxunk them into': 254695,\n",
       " 'them into two': 203604,\n",
       " 'into two countries': 114006,\n",
       " 'two countries .': 216920,\n",
       " 'countries . xxmaj': 66008,\n",
       " 'xxmaj there is': 245863,\n",
       " 'there is some': 204478,\n",
       " 'is some merit': 116653,\n",
       " 'some merit in': 182378,\n",
       " 'merit in this': 134930,\n",
       " 'in this view': 111835,\n",
       " 'this view ,': 208151,\n",
       " 'view , but': 220880,\n",
       " ', but it': 9890,\n",
       " \"but it 's\": 55696,\n",
       " \"it 's also\": 117600,\n",
       " \"'s also true\": 4429,\n",
       " 'also true that': 32184,\n",
       " 'true that no': 216023,\n",
       " 'that no one': 192776,\n",
       " 'no one forced': 144682,\n",
       " 'one forced xxmaj': 153657,\n",
       " 'forced xxmaj hindus': 88497,\n",
       " 'xxmaj muslims in': 242512,\n",
       " 'muslims in the': 140405,\n",
       " 'in the region': 111634,\n",
       " 'the region to': 199761,\n",
       " 'region to xxunk': 168795,\n",
       " 'to xxunk each': 213937,\n",
       " 'xxunk each other': 250837,\n",
       " 'each other as': 74858,\n",
       " 'other as they': 156153,\n",
       " 'as they did': 43783,\n",
       " 'they did around': 205225,\n",
       " 'did around the': 70506,\n",
       " 'around the time': 42555,\n",
       " 'the time of': 201151,\n",
       " 'time of partition': 209911,\n",
       " 'of partition .': 149425,\n",
       " 'partition . xxmaj': 158799,\n",
       " 'xxmaj it seems': 240801,\n",
       " 'it seems more': 119098,\n",
       " 'seems more likely': 175507,\n",
       " 'more likely that': 137147,\n",
       " 'likely that the': 127642,\n",
       " 'that the xxmaj': 193265,\n",
       " 'xxmaj british simply': 237013,\n",
       " 'british simply saw': 54372,\n",
       " 'simply saw the': 179763,\n",
       " 'saw the xxunk': 172850,\n",
       " 'the xxunk between': 202374,\n",
       " 'xxunk between the': 250017,\n",
       " 'between the xxunk': 51431,\n",
       " 'the xxunk and': 202358,\n",
       " 'xxunk and were': 249580,\n",
       " 'and were clever': 38444,\n",
       " 'were clever enough': 226239,\n",
       " 'clever enough to': 62405,\n",
       " 'enough to exploit': 77237,\n",
       " 'to exploit them': 211449,\n",
       " 'exploit them to': 80556,\n",
       " 'them to their': 203691,\n",
       " 'to their own': 213485,\n",
       " 'their own ends': 203203,\n",
       " 'own ends .': 157824,\n",
       " 'ends . \\n \\n ': 76696,\n",
       " '\\n \\n  xxmaj the': 500,\n",
       " 'xxmaj the result': 245703,\n",
       " 'the result is': 199837,\n",
       " 'result is that': 169928,\n",
       " 'is that there': 116827,\n",
       " 'that there is': 193278,\n",
       " 'there is much': 204463,\n",
       " 'is much cruelty': 115902,\n",
       " 'much cruelty and': 139810,\n",
       " 'cruelty and inhumanity': 67242,\n",
       " 'and inhumanity in': 35997,\n",
       " 'inhumanity in the': 112823,\n",
       " 'in the situation': 111667,\n",
       " 'the situation and': 200465,\n",
       " 'situation and this': 180248,\n",
       " 'and this is': 38045,\n",
       " 'this is very': 207390,\n",
       " 'is very unpleasant': 117172,\n",
       " 'very unpleasant to': 220510,\n",
       " 'unpleasant to remember': 218257,\n",
       " ...}"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veczr.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ngram_doc = veczr.transform(valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200x260373 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 93552 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ngram_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = veczr.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the same cult',\n",
       " 'the same dance',\n",
       " 'the same date',\n",
       " 'the same day',\n",
       " 'the same diner']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[200000:200005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarized Naive Bayes, using ngrams form CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = movie_reviews.train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(train_ngram_doc.sign(), y.items);\n",
    "\n",
    "preds = m.predict(val_ngram_doc.sign())\n",
    "(preds.T==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ricardofernandez/anaconda3/envs/deeplearning/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(train_ngram_doc, y.items);\n",
    "\n",
    "preds = m.predict(val_ngram_doc)\n",
    "(preds.T==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = LogisticRegression(C=0.1, dual=True)\n",
    "m2.fit(trn_x_ngram_sgn, y.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = m2.predict(val_x_ngram_sgn)\n",
    "(preds.T==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=True, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=50000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = LogisticRegression(C=0.0001, dual=True, max_iter=50000)\n",
    "m2.fit(train_ngram_doc_matrix, y.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = m2.predict(valid_ngram_doc_matrix)\n",
    "(preds.T==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
